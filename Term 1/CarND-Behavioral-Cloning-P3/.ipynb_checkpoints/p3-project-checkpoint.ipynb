{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 22953\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "flow() got an unexpected keyword argument 'samples_per_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3babbbd4eb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#train_datagen = train_datageneration.flow(X_train, Y_train, batch_size=100, samples_per_epoch=len(X_train), nb_epoch=EPOCHS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: flow() got an unexpected keyword argument 'samples_per_epoch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SET SOME PARAMETERS\n",
    "\n",
    "EPOCHS=10\n",
    "ch, row, col = 3, 160, 320  # camera format\n",
    "\n",
    "# Import data\n",
    "driving_csv = pd.read_csv(\"driving_data/driving_log.csv\")\n",
    "\n",
    "# Examine data\n",
    "print(\"Number of datapoints: %d\" % len(driving_csv))\n",
    "\n",
    "# Extract centre image and steering angle from table\n",
    "# Format: X_path: centre image name, y: steering angle\n",
    "X_path = [driving_csv.loc[i][0]\n",
    "           for i in range(len(driving_csv))]\n",
    "Steering_angles = [driving_csv.loc[i][6]\n",
    "            for i in range(len(driving_csv))]\n",
    "\n",
    "# Import images\n",
    "#X_images = [mpimg.imread(\"data/\"+ image_path) for image_path in X_path]\n",
    "X_images = [mpimg.imread(image_path) for image_path in X_path]\n",
    "\n",
    "# View image\n",
    "#def view_image():\n",
    "    #print(\"Images: %d\" % len(X_images))\n",
    "    #print(\"Sample image\")\n",
    "    #plt.imshow(X_images[0])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_images, Steering_angles, test_size=0.1, random_state=0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# training model\n",
    "\n",
    "# Normalise data\n",
    "datagen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "#train_datagen = train_datageneration.flow(X_train, Y_train, batch_size=100, samples_per_epoch=len(X_train), nb_epoch=EPOCHS)\n",
    "train_generator = datagen.flow(datagen.flow(X_train, Y_train, batch_size=32), samples_per_epoch=len(X_train), nb_epoch=EPOCHS)\n",
    "validation_generator = datagen.flow(X_test, Y_test, batch_size=100, samples_per_epoch=len(X_test), nb_epoch=EPOCHS)\n",
    "\n",
    "def get_coreai_model(time_len=1):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1., input_shape=(row, col, ch), output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(16, 20, 20, subsample=(16, 16), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 15, 15, subsample=(12, 12), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 12, 12, subsample=(9, 9), border_mode=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(96, 9, 9, subsample=(6, 6), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(128, 6, 6, subsample=(3, 3), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(256, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "    \n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(24, 5, 5, input_shape=(row, col, ch)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv layer 2, 5x5 kernel to 36@\n",
    "    model.add(Convolution2D(36, 5, 5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv layer 3, 5x5 kernel to 48@\n",
    "    model.add(Convolution2D(48, 5, 5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv layer 4, 3x3 kernel to 64@\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Conv layer 5, 3x3 kernel to 64@\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer 1, 1164 neurons\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Fc2, 100 neurons\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Fc3, 50 neurons\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Fc4, 10 neurons\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Output\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "              \n",
    "    return model\n",
    "    \n",
    "\n",
    "# Train model\n",
    "\n",
    "# view_image()\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch=10000, nb_epoch=EPOCHS, validation_data=validation_generator) \n",
    "\n",
    "#model.fit(train_generator, nb_epoch=EPOCHS, validation_split=0.1)\n",
    "\n",
    "with open(\"model.json\", \"w\") as f:\n",
    "    f.write(model.to_json())\n",
    "    \n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
