{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Light Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ... Accuracy = 0.591837\n",
      "EPOCH 2 ... Accuracy = 0.639456\n",
      "EPOCH 3 ... Accuracy = 0.612245\n",
      "EPOCH 4 ... Accuracy = 0.612245\n",
      "EPOCH 5 ... Accuracy = 0.612245\n",
      "EPOCH 6 ... Accuracy = 0.612245\n",
      "EPOCH 7 ... Accuracy = 0.612245\n",
      "EPOCH 8 ... Accuracy = 0.612245\n",
      "EPOCH 9 ... Accuracy = 0.612245\n",
      "EPOCH 10 ... Accuracy = 0.612245\n",
      "EPOCH 11 ... Accuracy = 0.612245\n",
      "EPOCH 12 ... Accuracy = 0.612245\n",
      "EPOCH 13 ... Accuracy = 0.612245\n",
      "EPOCH 14 ... Accuracy = 0.612245\n",
      "EPOCH 15 ... Accuracy = 0.612245\n",
      "EPOCH 16 ... Accuracy = 0.612245\n",
      "EPOCH 17 ... Accuracy = 0.612245\n",
      "EPOCH 18 ... Accuracy = 0.612245\n",
      "EPOCH 19 ... Accuracy = 0.612245\n",
      "EPOCH 20 ... Accuracy = 0.612245\n",
      "EPOCH 21 ... Accuracy = 0.612245\n",
      "EPOCH 22 ... Accuracy = 0.612245\n",
      "EPOCH 23 ... Accuracy = 0.612245\n",
      "EPOCH 24 ... Accuracy = 0.612245\n",
      "EPOCH 25 ... Accuracy = 0.612245\n",
      "EPOCH 26 ... Accuracy = 0.612245\n",
      "EPOCH 27 ... Accuracy = 0.612245\n",
      "EPOCH 28 ... Accuracy = 0.612245\n",
      "EPOCH 29 ... Accuracy = 0.619048\n",
      "EPOCH 30 ... Accuracy = 0.666667\n",
      "EPOCH 31 ... Accuracy = 0.734694\n",
      "EPOCH 32 ... Accuracy = 0.755102\n",
      "EPOCH 33 ... Accuracy = 0.741497\n",
      "EPOCH 34 ... Accuracy = 0.761905\n",
      "EPOCH 35 ... Accuracy = 0.802721\n",
      "EPOCH 36 ... Accuracy = 0.802721\n",
      "EPOCH 37 ... Accuracy = 0.802721\n",
      "EPOCH 38 ... Accuracy = 0.802721\n",
      "EPOCH 39 ... Accuracy = 0.795918\n",
      "EPOCH 40 ... Accuracy = 0.795918\n",
      "EPOCH 41 ... Accuracy = 0.802721\n",
      "EPOCH 42 ... Accuracy = 0.802721\n",
      "EPOCH 43 ... Accuracy = 0.823129\n",
      "EPOCH 44 ... Accuracy = 0.809524\n",
      "EPOCH 45 ... Accuracy = 0.850340\n",
      "EPOCH 46 ... Accuracy = 0.809524\n",
      "EPOCH 47 ... Accuracy = 0.836735\n",
      "EPOCH 48 ... Accuracy = 0.823129\n",
      "EPOCH 49 ... Accuracy = 0.802721\n",
      "EPOCH 50 ... Accuracy = 0.816326\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "class TLClassifier_Trainer:\n",
    "    def __init__(self):\n",
    "        self.debug = False\n",
    "        self.green_images = []\n",
    "        self.yellow_images = []\n",
    "        self.red_images = []\n",
    "        self.unknown_images = []\n",
    "        self.X_train = np.ndarray(shape=(0, 60, 40, 3))\n",
    "        self.Y_train = np.ndarray(shape=(0))\n",
    "        self.set_image_paths('./pics/GREEN/', \n",
    "                './pics/YELLOW/', \n",
    "                './pics/RED/', \n",
    "                './pics/UNKNOWN/')\n",
    "        self.EPOCHS = 50\n",
    "        self.BATCH_SIZE = 256\n",
    "\n",
    "    # scale images depending on extension/image type\n",
    "    def load_image(self, image_path):\n",
    "        \n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image,None,fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "        except (Exception):\n",
    "            print(\"unknown cv2 exception\")\n",
    "            return\n",
    "            \n",
    "        # scale image (0-255)\n",
    "        if image_path[-4:] == '.png':\n",
    "            image = image.astype(np.float32)*255\n",
    "      \n",
    "        # remove alpha channel if present\n",
    "        if image.shape[2] == 4:\n",
    "            b, g, r, a = cv2.split(image)\n",
    "            image = np.dstack((r,g,b))\n",
    "    \n",
    "        return image\n",
    "\n",
    "    def set_image_paths(self, green_file_path, yellow_file_path, red_file_path, unknown_file_path):\n",
    "        \n",
    "        # add images\n",
    "        images = []\n",
    "        labels = []\n",
    "        green_images=os.listdir(green_file_path) \n",
    "        for green_image_path in green_images:\n",
    "            if type(green_image_path)==type(\"string\"):\n",
    "                image = self.load_image(green_file_path + green_image_path)\n",
    "                self.green_images.append(image)\n",
    "                images.append(image)\n",
    "                labels.append(1)\n",
    "                #print(image.shape)\n",
    "    \n",
    "        yellow_images=os.listdir(yellow_file_path) \n",
    "        for yellow_image_path in yellow_images:\n",
    "            if type(yellow_image_path)==type(\"string\"):\n",
    "                image = self.load_image(yellow_file_path + yellow_image_path)\n",
    "                self.yellow_images.append(image)\n",
    "                images.append(image)\n",
    "                labels.append(2)\n",
    "                            \n",
    "        red_images=os.listdir(red_file_path) \n",
    "        for red_image_path in red_images:\n",
    "            if type(red_image_path)==type(\"string\"):\n",
    "                image = self.load_image(red_file_path + red_image_path)\n",
    "                self.red_images.append(image)\n",
    "                images.append(image)\n",
    "                labels.append(3)\n",
    "    \n",
    "        unknown_images=os.listdir(unknown_file_path) \n",
    "        for unknown_image_path in unknown_images:\n",
    "            if type(unknown_image_path)==type(\"string\"):\n",
    "                image = self.load_image(unknown_file_path + unknown_image_path)\n",
    "                self.unknown_images.append(image)\n",
    "                images.append(image)\n",
    "                labels.append(4)\n",
    "        \n",
    "        self.X_train = np.array(images)\n",
    "        # zero center\n",
    "        #self.X_train = (self.X_train - self.X_train.mean())\n",
    "        self.Y_train = np.array(labels)\n",
    "                \n",
    "    def LeNet(self, x):    \n",
    "        # Hyperparameters\n",
    "        mu = 0\n",
    "        sigma = 0.01\n",
    "        Padding='VALID'\n",
    "        W_lambda = 3.0\n",
    "    \n",
    "        conv1_W = tf.Variable(tf.truncated_normal(shape=(6, 4, 3, 80), mean = mu, stddev = sigma))\n",
    "        conv1_b = tf.Variable(tf.zeros(80))\n",
    "        conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=Padding) + conv1_b\n",
    "        if self.debug:\n",
    "            print(\"x shape: \", x.shape)\n",
    "            print(\"conv1_W shape: \", conv1_W.shape)\n",
    "            print(\"conv1_b shape: \", conv1_b.shape)\n",
    "            print(\"conv1 shape: \", conv1.shape)\n",
    "    \n",
    "        # L2 Regularization\n",
    "        conv1_W = -W_lambda*conv1_W\n",
    "        if self.debug:\n",
    "            print(\"conv1_W (after L2 1) shape: \", conv1_W.shape)\n",
    "    \n",
    "        # Activation.\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        if self.debug:\n",
    "            print(\"conv1 (after Activiateion) shape: \", conv1.shape)\n",
    "    \n",
    "        # Pooling...\n",
    "        conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=Padding)\n",
    "        if self.debug:\n",
    "            print(\"conv1 (after Pooling 1) shape: \", conv1.shape)\n",
    "    \n",
    "        # Layer 2: Convolutional...\n",
    "        conv2_W = tf.Variable(tf.truncated_normal(shape=(6, 4, 80, 16), mean = mu, stddev = sigma))\n",
    "        conv2_b = tf.Variable(tf.zeros(16))\n",
    "        conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=Padding) + conv2_b\n",
    "        if self.debug:\n",
    "            print(\"conv2_W shape: \", conv2_W.shape)\n",
    "            print(\"conv2_b shape: \", conv2_b.shape)\n",
    "            print(\"conv2 shape: \", conv2.shape)\n",
    "    \n",
    "        # L2 Regularization\n",
    "        conv2 = -W_lambda*conv2\n",
    "        if self.debug:\n",
    "            print(\"conv2 shape after L2: \", conv2.shape)\n",
    "    \n",
    "        # Activation.\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        if self.debug:\n",
    "            print(\"conv2 shapea fter activation: \", conv2.shape)\n",
    "    \n",
    "        # Pooling...\n",
    "        conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=Padding)\n",
    "        if self.debug:\n",
    "            print(\"conv2 shape after pooling: \", conv2.shape)\n",
    "    \n",
    "        # Flatten...\n",
    "        fc0   = flatten(conv2)\n",
    "    \n",
    "        # Layer 3: Fully Connected...\n",
    "        fc1_W = tf.Variable(tf.truncated_normal(shape=(1232,240), mean = mu, stddev = sigma))\n",
    "        fc1_b = tf.Variable(tf.zeros(240))\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"fc0\", fc0.shape)\n",
    "            print(\"fc1_W\", fc1_W.shape)\n",
    "            print(\"fc1_b\", fc1_b.shape)\n",
    "        fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "        if self.debug:\n",
    "            print(\"fc1\", fc1.shape)\n",
    "    \n",
    "        # Activation.\n",
    "        fc1    = tf.nn.relu(fc1)\n",
    "        if self.debug:\n",
    "            print(\"fc1 after Activation\", fc1.shape)\n",
    "    \n",
    "        # Layer 4: Fully Connected...\n",
    "        fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 84), mean = mu, stddev = sigma))\n",
    "        fc2_b  = tf.Variable(tf.zeros(84))\n",
    "        fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "        if self.debug:\n",
    "            print(\"fc2_W shape: \", fc2_W.shape)\n",
    "            print(\"fc2_b shape: \", fc2_b.shape)\n",
    "            print(\"fc2 shape: \", fc2.shape)\n",
    "    \n",
    "        # Activation.\n",
    "        fc2    = tf.nn.relu(fc2)\n",
    "        if self.debug:\n",
    "            print(\"fc2 shape after activation: \", fc2.shape)\n",
    "    \n",
    "        # Layer 5: Fully Connected. Input = 84. Output = 4.\n",
    "        fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 4), mean = mu, stddev = sigma))\n",
    "        fc3_b  = tf.Variable(tf.zeros(4))\n",
    "        logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "        if self.debug:\n",
    "            print(\"fc3_W shape: \", fc3_W.shape)\n",
    "            print(\"fc3_b shape: \", fc3_b.shape)\n",
    "            print(\"logits shape: \", logits.shape)\n",
    "    \n",
    "        return logits\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        def evaluate(X_data, Y_data):\n",
    "            num_examples = len(X_data)\n",
    "            total_accuracy = 0\n",
    "            sess = tf.get_default_session()\n",
    "            for offset in range(0, num_examples, self.BATCH_SIZE):\n",
    "                batch_x, batch_y = X_data[offset:offset+self.BATCH_SIZE], Y_data[offset:offset+self.BATCH_SIZE]\n",
    "                accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "                total_accuracy += (accuracy * len(batch_x))\n",
    "            return total_accuracy / num_examples\n",
    "    \n",
    "    \n",
    "        # split new training set\n",
    "        X_train, Y_train = shuffle(self.X_train, self.Y_train)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "        \n",
    "        ### Train model\n",
    "        x = tf.placeholder(tf.float32, (None, 60, 40, 3))\n",
    "        y = tf.placeholder(tf.int32, (None))\n",
    "        one_hot_y = tf.one_hot(self.Y_train, 4)\n",
    "\n",
    "        rate = 0.0001\n",
    "\n",
    "        logits = self.LeNet(tf.cast(self.X_train, tf.float32))\n",
    "        #print(\"X_train shape: \", self.X_train)\n",
    "\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "        loss_operation = tf.reduce_mean(cross_entropy)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "        training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "        accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            num_examples = len(X_train)\n",
    "    \n",
    "            print(\"Training...\")\n",
    "            print()\n",
    "            avg_accuracy=[]\n",
    "            for i in range(self.EPOCHS):\n",
    "                X_train, Y_train = shuffle(X_train, Y_train)\n",
    "                for offset in range(0, num_examples, self.BATCH_SIZE):\n",
    "                    end = offset + self.BATCH_SIZE\n",
    "                    batch_x, batch_y = X_train[offset:end], Y_train[offset:end]\n",
    "                    sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "                validation_accuracy = evaluate(X_val, Y_val)\n",
    "                if self.debug:\n",
    "                    print(\"EPOCH {} ...\".format(i+1), \"Accuracy = {:.6f}\".format(validation_accuracy))\n",
    "                if i > self.EPOCHS*2/3:\n",
    "                    rate = 0.00001\n",
    "        \n",
    "            saver.save(sess, './model')\n",
    "            print(\"Model saved\")\n",
    "\n",
    "trainer = TLClassifier_Trainer()\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TLClassifier:\n",
    "    def __init__(self):\n",
    "        #TODO load classifier\n",
    "        #with tf.Session() as sess:\n",
    "            #self.saver = tf.train.import_meta_graph('model.meta')\n",
    "            #self.saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    \n",
    "        self.x = tf.placeholder(tf.float32, (None, 60, 40, 3))\n",
    "        self.y = tf.placeholder(tf.int32, (None))\n",
    "        self.trainer = TLClassifier_Trainer()\n",
    "        self.logits = trainer.LeNet(tf.cast(self.x, tf.float32))\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.import_meta_graph('model.meta')\n",
    "        self.saver.restore(self.sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "    def get_classification(self, image):\n",
    "        \"\"\"Determines the color of the traffic light in the image\n",
    "        Args:\n",
    "            image (cv::Mat): image containing the traffic light\n",
    "        Returns:\n",
    "            int: ID of traffic light color (specified in styx_msgs/TrafficLight)\n",
    "        \"\"\"\n",
    "        #TODO implement light color prediction\n",
    "        \n",
    "        res = None\n",
    "        res = cv2.resize(image ,None,fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "        image = res.reshape(1, 60, 40, 3)\n",
    "        assert image.shape == ((1, 60, 40, 3))\n",
    "        print(self.logits)\n",
    "        print(self.x)\n",
    "        print(image)\n",
    "        prediction = self.sess.run(self.logits, feed_dict={self.x: image})\n",
    "        classification = np.argmax(prediction)\n",
    "\n",
    "classifier = TLClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_9:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"Placeholder_2:0\", shape=(?, 60, 40, 3), dtype=float32)\n",
      "[[[[ 34  58  64]\n",
      "   [ 36  58  64]\n",
      "   [ 34  58  64]\n",
      "   ..., \n",
      "   [185 153 118]\n",
      "   [189 151 121]\n",
      "   [189 151 121]]\n",
      "\n",
      "  [[ 26  50  56]\n",
      "   [ 39  63  69]\n",
      "   [ 30  54  60]\n",
      "   ..., \n",
      "   [185 151 121]\n",
      "   [189 150 122]\n",
      "   [189 151 121]]\n",
      "\n",
      "  [[ 31  57  63]\n",
      "   [ 28  52  58]\n",
      "   [ 32  56  62]\n",
      "   ..., \n",
      "   [191 151 116]\n",
      "   [190 149 124]\n",
      "   [190 150 122]]\n",
      "\n",
      "  ..., \n",
      "  [[ 31  62  71]\n",
      "   [ 33  62  69]\n",
      "   [ 33  59  66]\n",
      "   ..., \n",
      "   [ 23  46  48]\n",
      "   [ 25  49  49]\n",
      "   [ 18  46  46]]\n",
      "\n",
      "  [[ 35  62  72]\n",
      "   [ 29  58  65]\n",
      "   [ 37  63  69]\n",
      "   ..., \n",
      "   [ 32  55  57]\n",
      "   [ 26  49  51]\n",
      "   [ 16  40  40]]\n",
      "\n",
      "  [[ 36  64  71]\n",
      "   [ 37  66  73]\n",
      "   [ 30  56  63]\n",
      "   ..., \n",
      "   [ 28  51  53]\n",
      "   [ 32  53  55]\n",
      "   [ 23  44  46]]]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_10\n\t [[Node: Variable_10/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_10)]]\n\t [[Node: add_9/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_77_add_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Variable_10/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-8c8e7b79b540>\", line 39, in <module>\n    classifier = TLClassifier()\n  File \"<ipython-input-2-8c8e7b79b540>\", line 13, in __init__\n    self.logits = trainer.LeNet(tf.cast(self.x, tf.float32))\n  File \"<ipython-input-1-16f2a7e88a11>\", line 96, in LeNet\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(6, 4, 3, 80), mean = mu, stddev = sigma))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1971, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3046, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1604, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable_10\n\t [[Node: Variable_10/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_10)]]\n\t [[Node: add_9/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_77_add_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         c_api.TF_GetCode(status))\n\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_10\n\t [[Node: Variable_10/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_10)]]\n\t [[Node: add_9/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_77_add_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-18a8ee8886c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pics/GREEN/1ut30.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-8c8e7b79b540>\u001b[0m in \u001b[0;36mget_classification\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1118\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1315\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_10\n\t [[Node: Variable_10/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_10)]]\n\t [[Node: add_9/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_77_add_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Variable_10/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-8c8e7b79b540>\", line 39, in <module>\n    classifier = TLClassifier()\n  File \"<ipython-input-2-8c8e7b79b540>\", line 13, in __init__\n    self.logits = trainer.LeNet(tf.cast(self.x, tf.float32))\n  File \"<ipython-input-1-16f2a7e88a11>\", line 96, in LeNet\n    conv1_W = tf.Variable(tf.truncated_normal(shape=(6, 4, 3, 80), mean = mu, stddev = sigma))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1971, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3046, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1604, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable_10\n\t [[Node: Variable_10/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_10)]]\n\t [[Node: add_9/_71 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_77_add_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./pics/GREEN/1ut30.jpg')\n",
    "classifier.get_classification(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./pics/GREEN/1ut30.jpg')\n",
    "res = None\n",
    "res = cv2.resize(image ,None,fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "img = res.reshape(1, 60, 40, 3)\n",
    "assert img.shape == ((1, 60, 40, 3))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(image):\n",
    "   \n",
    "    image = cv2.resize(image,None,fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "    X = np.ndarray(shape=(60, 40, 3))\n",
    "    image = []\n",
    "    image.append(X)\n",
    "    X=np.array(image)\n",
    "    print(X.shape)\n",
    "\n",
    "    \n",
    "image = cv2.imread('./pics/GREEN/1ut30.jpg')\n",
    "test(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "             \n",
    "print(\"Green   : \", len(classifier.green_images))\n",
    "print(\"Yellow  : \", len(classifier.yellow_images))\n",
    "print(\"Red     : \", len(classifier.red_images))\n",
    "print(\"Unknown : \", len(classifier.unknown_images))\n",
    "print(\"X_train : \", classifier.X_train.shape)\n",
    "print(\"Y_train : \", classifier.Y_train.shape)\n",
    "n_classes = len(set(classifier.Y_train))\n",
    "print(\"Classes : \", n_classes)\n",
    "print(\"image size: \", classifier.X_train.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "print('Sample Images')\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(classifier.X_train[random.randint(0, len(classifier.X_train))])\n",
    "    \n",
    "def plot_images(index):\n",
    "    plt.imshow(classifier.X_train[index])\n",
    "    print(\"Image: \", classifier.Y_train[index])\n",
    "\n",
    "plot_images(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
